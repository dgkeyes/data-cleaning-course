---
title: "Introduction"
output:
  xaringan::moon_reader:
    css: ["style.css", "default"]
    lib_dir: libs
    df_print: paged
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
---

```{r child = "setup.Rmd"}
```

```{r html output, eval=TRUE, include=FALSE}
options(htmltools.dir.version = FALSE, htmltools.preserve.raw = FALSE)
```

```{r imgs setup, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)

```

```{r xaringan-tachyons, echo=FALSE, eval=TRUE}
xaringanExtra::use_tachyons()
```

```{r xaringan-extra-styles, eval=TRUE, echo=FALSE}
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,     
)
```

```{r load pkgs, echo=FALSE, eval=TRUE}
library(dplyr)
library(gt)
```

class: center, middle, dk-section-title
background-image:url("images/gawn-australia-_OUvt8kLf0s-unsplash.jpg")
background-size: cover
# What is Data Cleaning?

???
Hello and welcome to Data Cleaning with R.
Before we begin, let's define Data Cleaning. Let's look at some of the more common definitions.
---

class: center, middle

>.large["Mechanistic, time consuming process of identifying and fixing incomplete, inaccurate, irrelevant, or duplicated data"]

???
One popular definition describes data cleaning as a Mechanistic, time consuming process of identifying and fixing incomplete, inaccurate, irrelevant, or duplicated data
--

>.large["Tedious tasks that get in the way of extracting true value and insights from data"]

???
Others mention a series of annoying tasks that get in the way of extracting true insights from data
--

> .large["Not difficult, not _real_ work. Done (grudgingly) before the main analyses"]

???
and some say it is not difficult and not real work. that it is done grudgingly before the actual analyses.
---

class: center, middle

>.large["~~.gray[Mechanistic, time consuming]~~ process of identifying and _fixing_ incomplete, inaccurate, irrelevant, or duplicated data"]

>.large["~~.gray[Tedious tasks that get in the way of]~~ extracting true value and insights from data"]

> .large["~~.gray[Not difficult, not _real_ work. Done (grudgingly) before the main analyses"]~~]

???
I'd like to refute some of that. 
Data cleaning means fixing issues with our data to make them more usable. 

It is real work, and it is not trivial.
---

## Data cleaning:

.large[
A spectrum of **reusable data transformations**  to make data **usable** and to obtain more meaningful results from our analysis or visualization methods.] 

???

Let's try again. We can define data cleaning as a spectrum of data transformation steps to make data usable and to get more meaningful results from our workflows.

--

.large[
Has no single end product, because different systems and methods consume different input data formats and structures.] 

???

There is no one particular end product when we're cleaning data, because different programs take different inputs, and we need to adjust our approach for each one. Still, clean data has certan things in common that we will be discussing throughout this course.  

---

## Cleaning data involves:

???
When we need to clean our data, these are the three main steps in the process.

--

.large[
**1\.** Identifying specific **issues** that hinder an analysis, visualization, or reporting workflow.]  

???
First, we identify the issues that hinder our workflows
--

.large[
**2\.** Determining which approach or tool is needed to address each issue.] 

???
Then we determine which approach or tool we will need
--
.large[
**3\.** Transforming the data, making them more appropriate and valuable for a variety of downstream purposes.
]

???
Finally, we transform the data, making them more useful for various different purposes.

---

## Common Issues

.fl.w-50[

- Non-rectangular data  
- Unusable variable names
- Whitespace 
- Inconsistent letter case  
- Missing/implicit/misplaced grouping variables
]

.fl.w-50[
- Compound values  
- Duplicated values  
- Broken values  
- Empty rows and columns  
- Numbers stored as text  
]

???
While I was preparing this class, I noticed that 
most definitions of data cleaning mention fixing issues with the data, but these issues are often mentioned without descriptions or context. I collected the most common ones here.

Data in the real world usually have these issues. This list here is for reference,but we will deal with all of them at a later section of this course.
---

## Why data cleaning

???
We often need to clean our data simply to get our software to import the data, and behave as we expect it to.

--
.large[
- Enables downstream tasks by making data readable & usable  
]
???
Clean data makes downstream tasks possible.
--
.large[
- Saves time (rows and columns in a data object ready for use)  
]
???
Having clean data saves time, for example, by having tables with rows and columns on which we can immediately perform operations.
--
.large[
- Avoid potentially costly delays, or misinterpretations
]

???
After that, clean data is important to avoid delays, biases, or misinterpretations.

---

## Why data cleaning in R

???
Why should we use R for data cleaning.

Because, by working with code and not interactively with pointing and clicking, we leave a record of our actions which we can revisit whenever we want.
--
.large[
- Document and reproduce the process  
]
--
.large[
- Less time editing manually  
]
???
with R, we can work on large files or with many files at once, which saves us time and might not even be feasible if done by hand.
--
.large[
- Purpose-built tools available and well documented
]
???
I also like R so much for data cleaning because there are a number of tools and packages built specifically for this, which have good documentation and a large community of users ready to help us if we get stuck.
--
.large[
- Code can be reproduced and repurposed
] 
???
Finally, the code we write can be run many times and repurposed for new projects.
---
class: center, middle

# Examples

???
Let me show you some examples of what can happen when we don't clean our data.
---
class: middle, center

```{r, eval=TRUE, out.width = "96%", echo=FALSE}
knitr::include_graphics("images/drugs.png")
```

???
This graph is entirely fictional, but it is based on a real used by a pharmaceutical company. This chart shows drug sales in a year. If an executive wants to know which was the top selling drug that year, this plot can be misleading. 

Why is that?

Look at the labels in the axis. There are minor variations in how the drug names were stored in the original data, and this small issue snuck onto a final product.  There are two drugs with duplicate entries because the plotting software does not realize that a name with underscores between words should be the same as a name with spaces between word. The same happened with two names that vary in letter case, is in all upper case and the other one isnt.

In this situation, the top-selling drug is not the one the chart is showing, so this is misleading. This looks obvious, but these kinds of issues are common and they can go unnoticed if we are working, for example with many years worth of data for hundreds of drugs.

---
```{r, eval=TRUE, echo=FALSE}
isi <- 
tibble::tribble(
         ~Researcher, ~Publications,
      "James Wilson",      "19 $$$",
      "Colt Whitman",         "18*",
        "Jane Allen",         "17*",
        "Maria Dias",          "14",
   "Dr. Deavan Smith",           "9",
     "Angie Ramirez",           "7",
        "Ellen Dice",           "5",
    "Dr. Jane Allen",           "4",
  )

isi %>% gt %>%   tab_header(
  title = md("Faculty Productivity Bonuses"),
  subtitle = "2020 - School of Engineering"
)  %>% tab_footnote(locations = cells_column_labels(columns = "Publications"),
  footnote = md("**$$$**  Award winner, **\\***  Honorable mention")
) %>% 
  tab_options(table.font.size = px(28))
```

???
This other example is also fictional, but it is based on a report used at a university to award the most productive faculty member each year with a cash bonus. This is a simplified made up version, but it is another good example of the consequences of not cleaning data before making calculations.

Here, the same faculty members appears twice in the data, because for whatever reason some entries include  titles while the rest of the entries do not. This is also a simple fix, which could have avoided the administrative hassle and embarrassment of amending the award after it had already been paid to the wrong person. 

---

class: middle, center

```{r, eval=TRUE, out.width = "100%", echo=FALSE}
knitr::include_graphics("images/fishlandings.png")
```

.small[Source: [Kenya Ministry of Agriculture, Livestock and Fisheries](https://africaopendata.org/organization/kenya-ministry-of-agriculture-livestock-and-fisheries)]

???

This next example is real data, describing fisheries data for a lake in Kenya in 2016. There are no mistakes in the values, but the data are structured in a way that makes sense to humans but is harder to feed into any analysis. 

If we had to restructure multiple files with this complicated structure, say, for many lakes and many years, the process can become time consuming. Fortunately, we can do this more efficiently in R, and will do so in a later lesson.

---

</br>
.left[
```{r, eval=TRUE, out.width = "100%", echo=FALSE}
knitr::include_graphics("images/tymp.png")
```
]

.small[Source: Ojeda _et al._ [(1999)](https://doi.org/10.1006/jare.1999.0496)]

???
This next example is a table from a scientific publication. A lot of information is being presented here and if we were to try and import the contents of this table into our analysis software, we would most likely run into some trouble. 

Again, nothing is inherently wrong with this table, but sometimes we might be forced to import and work with these kinds of data sources
---

```{r, eval=TRUE, echo=FALSE}
set.seed(20)
gtcars %>%
  dplyr::select(1:3,bdy_style,hp,trq,ctry_origin) %>% 
  dplyr::filter(ctry_origin == "Italy" | ctry_origin == "Germany") %>% 
  dplyr::group_by(ctry_origin) %>%
  dplyr::sample_n(4) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(ctry_origin) %>%
  gt() %>%   tab_style(
    cell_text(size = '18px'),
    locations = list(cells_body(),
                     cells_column_labels(everything()),
                     cells_title()))
```

.small[source: `gt:gtcars` Luxury Automobiles Dataset]

???

This last example describes some fancy cars. Things are OK for the most part, but notice these rows that group the cars by their country of their manufacturer. This is informative and readable, but not ideal from an analysis perspective, and we will see why later on in the course.


These were just some examples, but hopefully you were able to recognize some of the more common issue in the data and relate them to things you may have seen in your own work.

---
class: inverse

## Your turn

1. Read this short blog [post](https://www.johndcook.com/blog/2021/01/12/data-pathology/) by John D. Cook.
.center[https://www.johndcook.com/blog/2021/01/12/data-pathology/]

2. Reflect on the amount (if any) of data cleaning you perform for your day-to-day work.

---

class: center, middle, dk-section-title
background-image:url("images/willian-justen-de-vasconcellos-JJEQ1SQhkEg-unsplash.jpg")
background-size: cover
# Data Cleaning is Analysis

---

### When we clean data, we make judgements and interpretations

- Are the data in a usable structure?

--

- What constitutes 'unwanted' variation?

--

- Is there any implicit information that needs to made explicit?

--

- What to do about missing data. 

---

class: inverse
## Your Turn

*quiz image goes here

---
class: center, middle

.large[After identifying issues in our data, we decide which tool is best suited to address them.]

--

## This is also data analysis.

--

>.large[Data cleaning is an important stage in most data analyses, not a single-use task of lesser importance.]

---

class: center, middle, dk-section-title
background-image:url("images/endri-killo-tvWqbeOaJnw-unsplash.jpg")
background-size: cover
# The Data Cleaning Process

---

class: middle, center

```{r, eval=TRUE, out.width = "110%", echo=FALSE}
knitr::include_graphics("images/workflow.png")
```

---
class: center, middle, dk-section-title
background-image:url("images/bence-boros-l3_9j916sh0-unsplash.jpg")
background-size: cover
# Course Logistics

---

## Requirements and Prerequisites
### You: 

- are familiar with basic data types and objects in R  

- can use functions and arguments  

- have R and RStudio running  

- can install and load packages


---

## Course conventions

- All packages available on **CRAN** (can be installed with .orange[`install.packages()`])   

--

- All slides are available in html format

--

- Package names in .b.rrured[red], preceded by 📦  

--

- Functions and operators in .b.orange[orange]  

--

- Relevant example data is provided in slides (see '**data-setup**' panels)  


---

# My setup

- R v4.0.3  

- RStudio v1.4.1103  

- Default theme and pane layout  

- Linux Mint 20.1

---

## Course setup


**1\.** Create a new RStudio project on your computer


**2\.** Download course materials (data needed for "your turn" exercises) with 
📦 .b.rrured[`usethis`]


```{r, eval=FALSE}
install.packages("usethis") # Install first if necessary
usethis::use_course("FINALURLHERE") # Download course materials 
```

**3\.** Copy the downloaded materials to the folder containing the RStudio project you created for this course. 


